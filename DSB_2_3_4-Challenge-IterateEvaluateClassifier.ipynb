{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "bnb = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('yelp_labelled.txt', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={0: 'Review', 1: 'Positive'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace punctuation \n",
    "df['Review'] = df.Review.str.replace(r'[^a-zA-Z\\d\\s:]', '')\n",
    "# make lower case\n",
    "df['Review'] = df['Review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wow loved this place</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crust is not good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not tasty and the texture was just nasty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stopped by during the late may bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Positive\n",
       "0                               wow loved this place         1\n",
       "1                                  crust is not good         0\n",
       "2           not tasty and the texture was just nasty         0\n",
       "3  stopped by during the late may bank holiday of...         1\n",
       "4  the selection on the menu was great and so wer...         1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Words used in positive reviews:\n",
    "goodwords = df.Review[df.Positive == 1].str.cat(sep=' ').split()\n",
    "#Words used in negative reviews:\n",
    "badwords = df.Review[df.Positive == 0].str.cat(sep=' ').split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: 1246 Negative: 1397\n"
     ]
    }
   ],
   "source": [
    "#Unique words from goodwords and badwords:\n",
    "print('Positive:', len(np.unique(goodwords)), 'Negative:', len(np.unique(badwords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"diffs\" contain lists of words unique to goodwords, badwords.\n",
    "gooddiff = np.setdiff1d(ar1=pd.Series(goodwords).value_counts().keys(),\n",
    "                   ar2=pd.Series(badwords).value_counts().keys())\n",
    "baddiff = np.setdiff1d(ar1=pd.Series(badwords).value_counts().keys().ravel(),\n",
    "                   ar2=pd.Series(goodwords).value_counts().keys().ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['great', 'delicious', 'fantastic', 'awesome', 'loved', 'perfect',\n",
       "       'excellent', 'spot', 'happy', 'wonderful', 'town', 'tender',\n",
       "       'enjoyed', 'bacon', 'reasonable', 'bread', 'steaks', 'options',\n",
       "       'incredible', 'fun', 'visit', 'wrong', 'moist', 'white', 'greek',\n",
       "       'generous', 'ambience', 'flavorful', 'beautiful', 'hummus',\n",
       "       'boyfriend', 'second', 'until', 'homemade', 'healthy', 'delish',\n",
       "       'perfectly', 'interesting', 'pleased', 'mouth', 'party', 'favorite',\n",
       "       'outstanding', 'decor', 'pita', 'melt', 'youre', 'wow', 'duck',\n",
       "       'regular', 'butter', 'recommendation', 'patio', 'fine', 'chef',\n",
       "       'cool'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reduce gooddiff to list of words that occur three or more times:\n",
    "good_df = pd.DataFrame(goodwords)\n",
    "good_freq = good_df[good_df[0].isin(gooddiff)]\n",
    "good_rank = pd.DataFrame(good_freq[0].value_counts()).reset_index()\n",
    "top_good = good_rank[good_rank[0] >= 3]['index']\n",
    "top_good.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove context-specific or coincidental words (words whose definitions are not inherently positive/negative, or are not associated with positive/negative food experiences):\n",
    "\n",
    "spot\n",
    "town\n",
    "bread\n",
    "bacon\n",
    "wrong\n",
    "steaks\n",
    "chef\n",
    "duck\n",
    "white\n",
    "greek\n",
    "hummus\n",
    "butter\n",
    "pita\n",
    "melt\n",
    "second\n",
    "boyfriend\n",
    "youre\n",
    "until"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_good_edited = ['great', 'delicious', 'fantastic', 'awesome', 'loved', 'perfect',\n",
    "       'excellent', 'happy', 'wonderful', 'tender', 'reasonable', 'enjoyed', 'incredible',\n",
    "       'visit', 'fun', 'options', 'favorite', 'patio',\n",
    "       'recommendation', 'fine', 'cool', 'healthy',\n",
    "       'regular', 'beautiful', 'party', 'homemade', 'perfectly', 'moist',\n",
    "       'flavorful', 'pleased', 'wow',\n",
    "       'decor', 'delish', 'outstanding', 'mouth', 'ambience',\n",
    "       'generous', 'interesting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['minutes', 'bad', 'wasnt', 'bland', 'slow', 'terrible', 'probably',\n",
       "       'waited', 'overpriced', 'rude', 'took', 'horrible', 'poor',\n",
       "       'should', 'mediocre', 'her', 'hard', 'money', 'management',\n",
       "       'either', 'waste', 'sick', 'anytime', '10', 'waiting', 'long', '30',\n",
       "       'disappointing', 'tasteless', 'avoid', 'zero', 'asked', 'barely',\n",
       "       'tables', 'business', 'elsewhere', 'sad', 'dry', 'why', 'look',\n",
       "       'sucked', 'live', 'disappointment', 'unfortunately', '1', 'average',\n",
       "       'dirty', 'location', '12', 'wanted', 'yourself', 'sashimi', 'ok',\n",
       "       'worse', 'restaurants', 'busy', 'guess', 'insulted', 'maybe',\n",
       "       'totally', 'stale', 'style', 'nasty', 'stomach', 'sucks', 'awful',\n",
       "       'lacked', 'else', 'none', 'edible', 'please', 'unless', 'total',\n",
       "       'frozen', 'literally', 'wouldnt', '35', 'rather', 'water', 'soggy',\n",
       "       'although', 'salt', 'watched', 'star'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_df = pd.DataFrame(badwords)\n",
    "bad_freq = bad_df[bad_df[0].isin(baddiff)]\n",
    "bad_rank = pd.DataFrame(bad_freq[0].value_counts()).reset_index()\n",
    "top_bad = bad_rank[bad_rank[0] >= 3]['index']\n",
    "top_bad.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removed words:\n",
    "\n",
    "probably\n",
    "her\n",
    "either\n",
    "30\n",
    "10\n",
    "1\n",
    "live\n",
    "sashimi\n",
    "star\n",
    "12\n",
    "35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_bad_edited = ['minutes', 'bad', 'wasnt', 'bland', 'slow', 'waited',\n",
    "       'terrible', 'overpriced', 'took', 'rude', 'hard', 'poor', 'management',\n",
    "        'money', 'mediocre', 'should', 'horrible',\n",
    "       'tasteless', 'waste', 'asked', 'waiting', 'tables',\n",
    "       'anytime', 'barely', 'avoid', 'disappointing', 'long', 'sick',\n",
    "       'zero', 'sucked', 'unfortunately', 'disappointment', 'location',\n",
    "       'business', 'sad', 'elsewhere', 'dirty', 'why', 'dry',\n",
    "       'average', 'look', 'restaurants', 'guess', 'maybe',\n",
    "       'watched', 'stomach', 'none', 'lacked', 'totally', 'sucks',\n",
    "       'wouldnt', 'please', 'nasty', 'else', 'wanted', 'insulted',\n",
    "       'water', 'edible', 'stale', 'busy', 'yourself', 'rather',\n",
    "       'literally', 'soggy', 'total', 'worse', 'salt', 'ok', 'unless',\n",
    "       'frozen', 'although', 'style', 'awful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_good = top_good.tolist()\n",
    "top_bad = top_bad.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = top_good + top_bad\n",
    "top_words_edited = top_good_edited + top_bad_edited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['great',\n",
       " 'delicious',\n",
       " 'fantastic',\n",
       " 'awesome',\n",
       " 'loved',\n",
       " 'perfect',\n",
       " 'excellent',\n",
       " 'happy',\n",
       " 'wonderful',\n",
       " 'tender',\n",
       " 'reasonable',\n",
       " 'enjoyed',\n",
       " 'incredible',\n",
       " 'visit',\n",
       " 'fun',\n",
       " 'options',\n",
       " 'favorite',\n",
       " 'patio',\n",
       " 'recommendation',\n",
       " 'fine',\n",
       " 'cool',\n",
       " 'healthy',\n",
       " 'regular',\n",
       " 'beautiful',\n",
       " 'party',\n",
       " 'homemade',\n",
       " 'perfectly',\n",
       " 'moist',\n",
       " 'flavorful',\n",
       " 'pleased',\n",
       " 'wow',\n",
       " 'decor',\n",
       " 'delish',\n",
       " 'outstanding',\n",
       " 'mouth',\n",
       " 'ambience',\n",
       " 'generous',\n",
       " 'interesting']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_good_edited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_word_list(keyword_list, spaces=True, show_heatmap=False, print_corrmat=False, show_keywords=False):\n",
    "    # Create new \"features\" DataFrame object and include terms to match:\n",
    "    features = df\n",
    "\n",
    "    for key in keyword_list:\n",
    "        if spaces == True:\n",
    "            features[str(key)] = features.Review.str.contains(' '+ str(key) + ' ', case=False)\n",
    "        elif spaces == False:\n",
    "            features[str(key)] = features.Review.str.contains(str(key), case=False)\n",
    "    \n",
    "    # Prepare Bernoulli Naïve Bayes arguments:\n",
    "    \n",
    "    data = features[keyword_list]\n",
    "    target = features['Positive']    \n",
    "\n",
    "    bnb.fit(data, target)\n",
    "    y_pred = bnb.predict(data)\n",
    "    \n",
    "    # Add 'prediction' column to features DataFrame:\n",
    "    \n",
    "    features['prediction'] = y_pred\n",
    "    \n",
    "    # Create correlation matrix and heatmap, with optional settings to show them:\n",
    "    \n",
    "    corrmat = features.corr()\n",
    "    \n",
    "    if show_heatmap == True:\n",
    "        plt.rcParams['figure.figsize'] = 12, 12\n",
    "        sns.heatmap(df.corr(), vmin=-.5, vmax=.5, square=True, cmap='RdBu_r')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('(Set \"show_heatmap=True\" to show heatmap)')\n",
    "              \n",
    "    if print_corrmat == True:          \n",
    "        print(corrmat)\n",
    "    else:\n",
    "        print('(Set \"print_corrmat=True\" to show correlation matrix)')\n",
    "\n",
    "    if show_keywords == True:\n",
    "        print(keyword_list)\n",
    "    else:\n",
    "        print('(Set \"show_keywords=True\" to show keyword list)')\n",
    "    \n",
    "    # Return relevant data in print statements:\n",
    "    \n",
    "    print('\\n')\n",
    "    print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "        data.shape[0],\n",
    "        (target != y_pred).sum()\n",
    "    ))    \n",
    "    \n",
    "    cvs = cross_val_score(bnb, data, target, cv=10)\n",
    "    print(\"Cross Validation Scores (10 Folds):\", cvs)\n",
    "    \n",
    "    print(\"Averaged Cross-Validation Score: \", cvs.mean())\n",
    "    \n",
    "    print(\"Bernoulli Naïve Bayes Score: \", bnb.score(data, target))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(target, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Set \"show_heatmap=True\" to show heatmap)\n",
      "(Set \"print_corrmat=True\" to show correlation matrix)\n",
      "(Set \"show_keywords=True\" to show keyword list)\n",
      "\n",
      "\n",
      "Number of mislabeled points out of a total 1000 points : 352\n",
      "Cross Validation Scores (10 Folds): [ 0.65  0.64  0.63  0.6   0.67  0.61  0.71  0.65  0.64  0.66]\n",
      "Averaged Cross-Validation Score:  0.646\n",
      "Bernoulli Naïve Bayes Score:  0.648\n",
      "Confusion Matrix:\n",
      " [[500   0]\n",
      " [352 148]]\n"
     ]
    }
   ],
   "source": [
    "test_word_list(top_good_edited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Set \"show_heatmap=True\" to show heatmap)\n",
      "(Set \"print_corrmat=True\" to show correlation matrix)\n",
      "(Set \"show_keywords=True\" to show keyword list)\n",
      "\n",
      "\n",
      "Number of mislabeled points out of a total 1000 points : 284\n",
      "Cross Validation Scores (10 Folds): [ 0.68  0.7   0.7   0.7   0.75  0.7   0.76  0.73  0.72  0.71]\n",
      "Averaged Cross-Validation Score:  0.715\n",
      "Bernoulli Naïve Bayes Score:  0.716\n",
      "Confusion Matrix:\n",
      " [[496   4]\n",
      " [280 220]]\n"
     ]
    }
   ],
   "source": [
    "test_word_list(top_good_edited, spaces=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Set \"show_heatmap=True\" to show heatmap)\n",
      "(Set \"print_corrmat=True\" to show correlation matrix)\n",
      "(Set \"show_keywords=True\" to show keyword list)\n",
      "\n",
      "\n",
      "Number of mislabeled points out of a total 1000 points : 307\n",
      "Cross Validation Scores (10 Folds): [ 0.65  0.7   0.65  0.65  0.68  0.7   0.68  0.73  0.73  0.68]\n",
      "Averaged Cross-Validation Score:  0.685\n",
      "Bernoulli Naïve Bayes Score:  0.693\n",
      "Confusion Matrix:\n",
      " [[193 307]\n",
      " [  0 500]]\n"
     ]
    }
   ],
   "source": [
    "test_word_list(top_bad_edited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Set \"show_heatmap=True\" to show heatmap)\n",
      "(Set \"print_corrmat=True\" to show correlation matrix)\n",
      "(Set \"show_keywords=True\" to show keyword list)\n",
      "\n",
      "\n",
      "Number of mislabeled points out of a total 1000 points : 243\n",
      "Cross Validation Scores (10 Folds): [ 0.7   0.78  0.71  0.71  0.7   0.77  0.79  0.78  0.76  0.76]\n",
      "Averaged Cross-Validation Score:  0.746\n",
      "Bernoulli Naïve Bayes Score:  0.757\n",
      "Confusion Matrix:\n",
      " [[268 232]\n",
      " [ 11 489]]\n"
     ]
    }
   ],
   "source": [
    "test_word_list(top_bad_edited, spaces=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Set \"show_heatmap=True\" to show heatmap)\n",
      "(Set \"print_corrmat=True\" to show correlation matrix)\n",
      "(Set \"show_keywords=True\" to show keyword list)\n",
      "\n",
      "\n",
      "Number of mislabeled points out of a total 1000 points : 307\n",
      "Cross Validation Scores (10 Folds): [ 0.65  0.7   0.65  0.65  0.68  0.7   0.68  0.73  0.73  0.68]\n",
      "Averaged Cross-Validation Score:  0.685\n",
      "Bernoulli Naïve Bayes Score:  0.693\n",
      "Confusion Matrix:\n",
      " [[193 307]\n",
      " [  0 500]]\n"
     ]
    }
   ],
   "source": [
    "test_word_list(top_words_edited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Set \"show_heatmap=True\" to show heatmap)\n",
      "(Set \"print_corrmat=True\" to show correlation matrix)\n",
      "(Set \"show_keywords=True\" to show keyword list)\n",
      "\n",
      "\n",
      "Number of mislabeled points out of a total 1000 points : 239\n",
      "Cross Validation Scores (10 Folds): [ 0.71  0.8   0.72  0.72  0.72  0.78  0.79  0.79  0.77  0.8 ]\n",
      "Averaged Cross-Validation Score:  0.76\n",
      "Bernoulli Naïve Bayes Score:  0.761\n",
      "Confusion Matrix:\n",
      " [[268 232]\n",
      " [  7 493]]\n"
     ]
    }
   ],
   "source": [
    "test_word_list(top_words_edited, spaces=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Set \"show_heatmap=True\" to show heatmap)\n",
      "(Set \"print_corrmat=True\" to show correlation matrix)\n",
      "(Set \"show_keywords=True\" to show keyword list)\n",
      "\n",
      "\n",
      "Number of mislabeled points out of a total 1000 points : 320\n",
      "Cross Validation Scores (10 Folds): [ 0.68  0.67  0.65  0.64  0.71  0.64  0.75  0.66  0.69  0.69]\n",
      "Averaged Cross-Validation Score:  0.678\n",
      "Bernoulli Naïve Bayes Score:  0.68\n",
      "Confusion Matrix:\n",
      " [[500   0]\n",
      " [320 180]]\n"
     ]
    }
   ],
   "source": [
    "test_word_list(top_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Set \"show_heatmap=True\" to show heatmap)\n",
      "(Set \"print_corrmat=True\" to show correlation matrix)\n",
      "(Set \"show_keywords=True\" to show keyword list)\n",
      "\n",
      "\n",
      "Number of mislabeled points out of a total 1000 points : 290\n",
      "Cross Validation Scores (10 Folds): [ 0.65  0.71  0.67  0.7   0.68  0.71  0.69  0.76  0.74  0.69]\n",
      "Averaged Cross-Validation Score:  0.7\n",
      "Bernoulli Naïve Bayes Score:  0.71\n",
      "Confusion Matrix:\n",
      " [[210 290]\n",
      " [  0 500]]\n"
     ]
    }
   ],
   "source": [
    "test_word_list(top_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Set \"show_heatmap=True\" to show heatmap)\n",
      "(Set \"print_corrmat=True\" to show correlation matrix)\n",
      "(Set \"show_keywords=True\" to show keyword list)\n",
      "\n",
      "\n",
      "Number of mislabeled points out of a total 1000 points : 290\n",
      "Cross Validation Scores (10 Folds): [ 0.65  0.71  0.67  0.7   0.68  0.71  0.69  0.76  0.74  0.69]\n",
      "Averaged Cross-Validation Score:  0.7\n",
      "Bernoulli Naïve Bayes Score:  0.71\n",
      "Confusion Matrix:\n",
      " [[210 290]\n",
      " [  0 500]]\n"
     ]
    }
   ],
   "source": [
    "test_word_list(top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
